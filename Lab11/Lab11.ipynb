{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторна робота 11\n",
    "\n",
    "\n",
    "Вступ до Natural Language Processing (NLP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мета: Познайомитися з основними поняттями, методами та підходами у сфері обробки природної мови (NLP).\n",
    "\n",
    "\n",
    " Провести порівняльний аналіз популярних алгоритмів та інструментів, а також підготувати презентацію на цю тему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Токенізація: ['Природна', 'мова', 'є', 'складним', 'і', 'багатозначним', 'явищем', '.']\n",
      "Лемми: ['Природна', 'мова', 'є', 'складним', 'і', 'багатозначним', 'явищем', '.']\n",
      "Стовбури: ['природна', 'мова', 'є', 'складним', 'і', 'багатозначним', 'явищем', '.']\n",
      "Bag of Words: [[1 1 1 1 1]]\n",
      "TF-IDF: [[0.4472136 0.4472136 0.4472136 0.4472136 0.4472136]]\n",
      "Word Embedding для 'мова': [ 8.13227147e-03 -4.45733406e-03 -1.06835726e-03  1.00636482e-03\n",
      " -1.91113955e-04  1.14817743e-03  6.11386076e-03 -2.02715401e-05\n",
      " -3.24596534e-03 -1.51072862e-03  5.89729892e-03  1.51410222e-03\n",
      " -7.24261976e-04  9.33324732e-03 -4.92128357e-03 -8.38409644e-04\n",
      "  9.17541143e-03  6.74942741e-03  1.50285603e-03 -8.88256077e-03\n",
      "  1.14874600e-03 -2.28825561e-03  9.36823711e-03  1.20992784e-03\n",
      "  1.49006362e-03  2.40640994e-03 -1.83600665e-03 -4.99963388e-03\n",
      "  2.32429506e-04 -2.01418041e-03  6.60093315e-03  8.94012302e-03\n",
      " -6.74754381e-04  2.97701475e-03 -6.10765442e-03  1.69932481e-03\n",
      " -6.92623248e-03 -8.69402662e-03 -5.90020278e-03 -8.95647518e-03\n",
      "  7.27759488e-03 -5.77203138e-03  8.27635173e-03 -7.24354526e-03\n",
      "  3.42167495e-03  9.67499893e-03 -7.78544787e-03 -9.94505733e-03\n",
      " -4.32914635e-03 -2.68313056e-03 -2.71289347e-04 -8.83155130e-03\n",
      " -8.61755759e-03  2.80021061e-03 -8.20640661e-03 -9.06933658e-03\n",
      " -2.34046578e-03 -8.63180775e-03 -7.05664977e-03 -8.40115082e-03\n",
      " -3.01328895e-04 -4.56429832e-03  6.62717456e-03  1.52716041e-03\n",
      " -3.34147573e-03  6.10897178e-03 -6.01328490e-03 -4.65616956e-03\n",
      " -7.20750913e-03 -4.33658017e-03 -1.80932996e-03  6.48964290e-03\n",
      " -2.77039292e-03  4.91896737e-03  6.90444233e-03 -7.46370573e-03\n",
      "  4.56485013e-03  6.12697843e-03 -2.95447465e-03  6.62502181e-03\n",
      "  6.12587947e-03 -6.44348515e-03 -6.76455162e-03  2.53895880e-03\n",
      " -1.62381888e-03 -6.06512791e-03  9.49920900e-03 -5.13014663e-03\n",
      " -6.55409694e-03 -1.19885204e-04 -2.70142802e-03  4.44400299e-04\n",
      " -3.53745813e-03 -4.19330609e-04 -7.08615757e-04  8.22820642e-04\n",
      "  8.19481723e-03 -5.73670724e-03 -1.65952800e-03  5.57160750e-03]\n",
      "Класифікація тексту з наївним баєсовим класифікатором: [1]\n",
      "Розпізнавання сутностей: [('Україні', 'LOC')]\n",
      "Порівняльна таблиця методів векторизації тексту:\n",
      "         Method                      Advantages                 Disadvantages  \\\n",
      "0  Bag of Words                        Простота      Не враховує порядок слів   \n",
      "1        TF-IDF        Знижує вплив частих слів  Може не враховувати контекст   \n",
      "2      Word2Vec  Зберігає семантичні відношення     Високі вимоги до ресурсів   \n",
      "\n",
      "              Applications Scalability  \n",
      "0             Класифікація      Низька  \n",
      "1       Аналіз тональності     Середня  \n",
      "2  Нейронні мережі для NLP      Висока  \n",
      "Порівняльна таблиця інструментів NLP:\n",
      "                        Tool                       Main Features  \\\n",
      "0                       NLTK  Токенізація, стемінг, лемматизація   \n",
      "1                      SpaCy                     NER, POS-тегінг   \n",
      "2  Hugging Face Transformers     Підтримка моделей трансформерів   \n",
      "3                     Gensim                     Word Embeddings   \n",
      "\n",
      "  Languages Supported Ease of Use  \n",
      "0          Багато мов     Середня  \n",
      "1  Англійська та інші      Висока  \n",
      "2          Багато мов      Висока  \n",
      "3          Багато мов     Середня  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from gensim.models import Word2Vec\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Завантажуємо модель spacy для української мови\n",
    "nlp_uk = spacy.load(\"uk_core_news_sm\")\n",
    "\n",
    "# 1. Токенізація (спробуємо з spacy для української мови)\n",
    "text = \"Природна мова є складним і багатозначним явищем.\"\n",
    "doc = nlp_uk(text)\n",
    "tokens = [token.text for token in doc]\n",
    "print(\"Токенізація:\", tokens)\n",
    "\n",
    "# 2. Лемматизація та стемінг\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Лемматизація\n",
    "lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "# Стемінг\n",
    "stems = [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "print(\"Лемми:\", lemmas)\n",
    "print(\"Стовбури:\", stems)\n",
    "\n",
    "# 3. Векторизація тексту\n",
    "# Bag of Words (BOW)\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_bow = vectorizer_bow.fit_transform([text]).toarray()\n",
    "print(\"Bag of Words:\", X_bow)\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform([text]).toarray()\n",
    "print(\"TF-IDF:\", X_tfidf)\n",
    "\n",
    "# Word Embeddings (Word2Vec)\n",
    "sentences = [tokens]\n",
    "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "word_vector = w2v_model.wv['мова']\n",
    "print(\"Word Embedding для 'мова':\", word_vector)\n",
    "\n",
    "# 4. Класифікація тексту\n",
    "X = vectorizer_bow.fit_transform([\"Тестовий текст для класифікації\"])\n",
    "y = [1]  # Приклад міток\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X, y)\n",
    "print(\"Класифікація тексту з наївним баєсовим класифікатором:\", nb_model.predict(X))\n",
    "\n",
    "# 5. Розпізнавання сутностей (NER)\n",
    "doc = nlp_uk(\"Баришівка - місто в Україні.\")\n",
    "print(\"Розпізнавання сутностей:\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "# Порівняльний аналіз методів векторизації\n",
    "vectorization_data = {\n",
    "    \"Method\": [\"Bag of Words\", \"TF-IDF\", \"Word2Vec\"],\n",
    "    \"Advantages\": [\"Простота\", \"Знижує вплив частих слів\", \"Зберігає семантичні відношення\"],\n",
    "    \"Disadvantages\": [\"Не враховує порядок слів\", \"Може не враховувати контекст\", \"Високі вимоги до ресурсів\"],\n",
    "    \"Applications\": [\"Класифікація\", \"Аналіз тональності\", \"Нейронні мережі для NLP\"],\n",
    "    \"Scalability\": [\"Низька\", \"Середня\", \"Висока\"]\n",
    "}\n",
    "df_vectorization = pd.DataFrame(vectorization_data)\n",
    "print(\"Порівняльна таблиця методів векторизації тексту:\")\n",
    "print(df_vectorization)\n",
    "\n",
    "# Порівняльний аналіз інструментів NLP\n",
    "nlp_tools_data = {\n",
    "    \"Tool\": [\"NLTK\", \"SpaCy\", \"Hugging Face Transformers\", \"Gensim\"],\n",
    "    \"Main Features\": [\"Токенізація, стемінг, лемматизація\", \"NER, POS-тегінг\", \"Підтримка моделей трансформерів\", \"Word Embeddings\"],\n",
    "    \"Languages Supported\": [\"Багато мов\", \"Англійська та інші\", \"Багато мов\", \"Багато мов\"],\n",
    "    \"Ease of Use\": [\"Середня\", \"Висока\", \"Висока\", \"Середня\"]\n",
    "}\n",
    "df_nlp_tools = pd.DataFrame(nlp_tools_data)\n",
    "print(\"Порівняльна таблиця інструментів NLP:\")\n",
    "print(df_nlp_tools)\n",
    "\n",
    "# Збереження результатів у .csv файли локально з правильним кодуванням\n",
    "df_vectorization.to_csv(\"vectorization_comparison.csv\", index=False, encoding='utf-8-sig')\n",
    "df_nlp_tools.to_csv(\"nlp_tools_comparison.csv\", index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('uk_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "download('uk_core_news_sm')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
